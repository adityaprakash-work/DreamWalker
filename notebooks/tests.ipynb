{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-23 09:43:59,509 DEBUG MainThread matplotlib matplotlib data path: c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\mpl-data\n",
      "2023-12-23 09:43:59,512 DEBUG MainThread matplotlib CONFIGDIR=C:\\Users\\adity\\.matplotlib\n",
      "2023-12-23 09:43:59,512 DEBUG MainThread matplotlib interactive is False\n",
      "2023-12-23 09:43:59,519 DEBUG MainThread matplotlib platform is win32\n",
      "2023-12-23 09:43:59,642 DEBUG MainThread matplotlib CACHEDIR=C:\\Users\\adity\\.matplotlib\n",
      "2023-12-23 09:43:59,650 DEBUG MainThread matplotlib.font_manager Using fontManager instance from C:\\Users\\adity\\.matplotlib\\fontlist-v330.json\n",
      "2023-12-23 09:44:05,197 DEBUG MainThread tensorflow Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "2023-12-23 09:44:05,734 DEBUG MainThread h5py._conv Creating converter from 7 to 5\n",
      "2023-12-23 09:44:05,734 DEBUG MainThread h5py._conv Creating converter from 5 to 7\n",
      "2023-12-23 09:44:05,738 DEBUG MainThread h5py._conv Creating converter from 7 to 5\n",
      "2023-12-23 09:44:05,739 DEBUG MainThread h5py._conv Creating converter from 5 to 7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "import dreamwalker.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheeg.models.transformer.conformer import (\n",
    "    PatchEmbedding,\n",
    "    TransformerEncoder,\n",
    ")\n",
    "\n",
    "from dreamwalker.models.misc import ResidualStack\n",
    "\n",
    "\n",
    "# ---CONFORMER EEG ENCODER------------------------------------------------------\n",
    "class ConformerEEGEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_electrodes: int = 128,\n",
    "        num__samples: int = 500,\n",
    "        sampling_rate: int = 100,\n",
    "        embed_dropout: float = 0.5,\n",
    "        hid_channels: int = 40,\n",
    "        depth: int = 6,\n",
    "        heads: int = 10,\n",
    "        dropout: float = 0.5,\n",
    "        forward_expansion: int = 4,\n",
    "        forward_dropout: float = 0.5,\n",
    "        lat_shape: tuple = (16, 32, 32),\n",
    "        num_res_blocks: int = 1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_electrodes = num_electrodes\n",
    "        self.num__samples = num__samples\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.embed_dropout = embed_dropout\n",
    "        self.hid_channels = hid_channels\n",
    "        self.depth = depth\n",
    "        self.heads = heads\n",
    "        self.dropout = dropout\n",
    "        self.forward_expansion = forward_expansion\n",
    "        self.forward_dropout = forward_dropout\n",
    "        self.lat_shape = lat_shape\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "\n",
    "        self.emb = PatchEmbedding(num_electrodes, hid_channels, embed_dropout)\n",
    "        self.enc = TransformerEncoder(\n",
    "            depth,\n",
    "            hid_channels,\n",
    "            heads=heads,\n",
    "            dropout=dropout,\n",
    "            forward_expansion=forward_expansion,\n",
    "            forward_dropout=forward_dropout,\n",
    "        )\n",
    "\n",
    "        entr_units = self.get_mock_shape()\n",
    "        entr_units = entr_units[1] * entr_units[2]\n",
    "        exit_units = self.lat_shape[0] * self.lat_shape[1] * self.lat_shape[2]\n",
    "        betw_units = (entr_units + exit_units) // 2\n",
    "\n",
    "        # Correction FC\n",
    "        self.cfc = nn.Sequential(\n",
    "            nn.Linear(entr_units, betw_units),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(betw_units, exit_units),\n",
    "        )\n",
    "\n",
    "        # Residual Stack\n",
    "        self.rst = ResidualStack(\n",
    "            self.lat_shape[0], self.lat_shape[0], n_residual_blocks=num_res_blocks\n",
    "        )\n",
    "\n",
    "    def get_mock_shape(self):\n",
    "        x = torch.rand(1, 1, self.num_electrodes, self.num__samples)\n",
    "        x = self.emb(x)\n",
    "        x = self.enc(x)\n",
    "        return x.shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.enc(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.cfc(x)\n",
    "        x = x.view(x.shape[0], *self.lat_shape)\n",
    "        x = self.rst(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mc\u001b[49m\u001b[38;5;241m.\u001b[39mget_mock_shape()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "c.get_mock_shape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
