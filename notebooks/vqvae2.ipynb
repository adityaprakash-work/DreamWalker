{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DEPENDENCIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local import\n",
    "# import sys\n",
    "# sys.path.append('..')\n",
    "\n",
    "# Import on colab\n",
    "%pip install git+https://github.com/adityaprakash-work/DreamWalker.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive; drive.mount('/content/drive')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import dreamwalker as dw\n",
    "from dreamwalker.pytorch_generative import models, trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load from an online source\n",
    "dataset_url = \"https://www.kaggle.com/datasets/ifigotin/imagenetmini-1000/data\"\n",
    "dataset_dir = \"/content/dataset\"\n",
    "dw.utils.datasets.download(dataset_url, dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/content/dataset/imagenetmini-1000/imagenet-mini/train\"\n",
    "valid_dir = \"/content/dataset/imagenetmini-1000/imagenet-mini/val\"\n",
    "if valid_dir is None:\n",
    "    dataset = dw.utils.datasets.ImageStream(train_dir, ext=\"JPEG\")\n",
    "    train_loader, valid_loader = dw.utils.datasets.get_loaders(\n",
    "        dataset, return_valid=True, valid_size=0.2\n",
    "    )\n",
    "\n",
    "else:\n",
    "    train_dataset = dw.utils.datasets.ImageStream(train_dir, ext=\"JPEG\")\n",
    "    valid_dataset = dw.utils.datasets.ImageStream(valid_dir, ext=\"JPEG\")\n",
    "    train_loader = dw.utils.datasets.get_loaders(train_dataset, batch_size=16)\n",
    "    valid_loader = dw.utils.datasets.get_loaders(valid_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, _ in train_loader:\n",
    "    print(data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.VectorQuantizedVAE2(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    hidden_channels=128,\n",
    "    n_residual_blocks=2,\n",
    "    residual_channels=64,\n",
    "    n_embeddings=512,\n",
    "    embedding_dim=64,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
    "scheduler = lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lambda _: 0.999977)\n",
    "\n",
    "def loss_fn(x, _, preds):\n",
    "    preds, vq_loss = preds\n",
    "    recon_loss = F.mse_loss(preds, x)\n",
    "    loss = recon_loss + 0.25 * vq_loss\n",
    "\n",
    "    return {\n",
    "        \"vq_loss\": vq_loss,\n",
    "        \"reconstruction_loss\": recon_loss,\n",
    "        \"loss\": loss,\n",
    "    }\n",
    "\n",
    "model_trainer = trainer.Trainer(\n",
    "    model=model, \n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    eval_loader=valid_loader,\n",
    "    lr_scheduler=scheduler,\n",
    "    log_dir=\"/content/logs/vqvae0\",\n",
    "    n_gpus=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make grid of original vs reconstructed images\n",
    "def make_grid_ovsr(original, reconstructions):\n",
    "    num_samples=original.shape[0]\n",
    "    num_rows = int(np.ceil(np.sqrt(num_samples)))\n",
    "    grid_o = make_grid(original, nrow=num_rows, normalize=True)\n",
    "    grid_r = make_grid(reconstructions, nrow=num_rows, normalize=True)\n",
    "    grid = torch.cat([grid_o, grid_r], dim=-1)\n",
    "    return grid\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def recplt_monitor(model_trainer):\n",
    "    model_trainer.model.eval()\n",
    "    x, _ = next(iter(model_trainer.eval_loader))\n",
    "    x = x.to(model_trainer.device)\n",
    "    x_recon, _ = model_trainer.model(x)\n",
    "    x = x.cpu().detach()\n",
    "    x_recon = x_recon.cpu().detach()\n",
    "    model_trainer._summary_writer.add_image(\n",
    "        \"Reconstruction Fidelity\",\n",
    "        make_grid_ovsr(x, x_recon),\n",
    "        model_trainer._step,\n",
    "    )\n",
    "    model_trainer.model.train()\n",
    "    \n",
    "\n",
    "model_trainer.interleaved_train_and_eval(5, arbitrary_monitors=[recplt_monitor])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
